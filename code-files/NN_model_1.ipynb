{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7503f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import MSE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e848e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b82c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where the input and output data are located\n",
    "NN_data_path = \"/fmi/projappl/project_2004400/jamin/data/libradtran_data/NN_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bacb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(NN_data_path + \"inputs.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4ff040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HDF5(folder_path: str, file_name: str):\n",
    "    \"\"\"\n",
    "    Reads in the output data for the NN model.\n",
    "    \n",
    "    Args:\n",
    "        folder_path: path to the folder containing the output data\n",
    "        file_name: name of the output data file\n",
    "        \n",
    "    Returns:\n",
    "        output_data: a NumPy array (tensor) containing the output data.\n",
    "    \"\"\"\n",
    "    with h5py.File(name=folder_path+file_name, mode=\"r\") as hf:\n",
    "        data = hf[\"output_data\"][:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87ba2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = load_HDF5(NN_data_path, \"outputs_subset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a83787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (X) shape: (1728, 54)\n",
      "Output (Y) shape: (1728, 235002, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input (X) shape: {X.shape}\")\n",
    "print(f\"Output (Y) shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3db8ff",
   "metadata": {},
   "source": [
    "- Note that the 8 columns of **Y** correspond to these variable (in this order): tdir_down, tdif_down, tdir_up, tdif_up, spherical_albedo, edir, edif, path_rad.\n",
    "- The order can be seen from the *create_subset* function in [THIS](https://github.com/monsieurformule/SummerProject/blob/main/code-files/Generate_NN_outputs.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c1797",
   "metadata": {},
   "source": [
    "Note that there are **1728** *matrices*, where each matrix of shape $\\, (235002, 8) \\,$ corresponds to one row in the inputs matrix. This leaves us with two choices:\n",
    "\n",
    "**1)** Build a NN where each input row predicts a matrix of shape $\\, (235002, 8). \\,$ \\\n",
    "**2)** Build **8** separate NNs, where each NN is taught to predict one vector of shape $\\, (235002, 1). \\,$\n",
    "\n",
    "In this notebook, we'll build **8** separate neural networks that each predicts a different feature of shape $\\, (235002, 1). \\,$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bec03",
   "metadata": {},
   "source": [
    "<h3>Preparing the data for the neural network(s)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cf513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atmosphere_file</th>\n",
       "      <th>sza</th>\n",
       "      <th>altitude</th>\n",
       "      <th>tau</th>\n",
       "      <th>2e-05</th>\n",
       "      <th>4e-05</th>\n",
       "      <th>6e-05</th>\n",
       "      <th>0.00012</th>\n",
       "      <th>0.00026</th>\n",
       "      <th>0.00062</th>\n",
       "      <th>...</th>\n",
       "      <th>324.0</th>\n",
       "      <th>372.0</th>\n",
       "      <th>426.0</th>\n",
       "      <th>487.0</th>\n",
       "      <th>554.0</th>\n",
       "      <th>628.0</th>\n",
       "      <th>710.0</th>\n",
       "      <th>802.0</th>\n",
       "      <th>902.0</th>\n",
       "      <th>1013.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afglms_Q1_0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afglms_Q1_0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afglms_Q1_0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afglms_Q1_0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afglms_Q1_0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  atmosphere_file   sza  altitude   tau     2e-05     4e-05     6e-05  \\\n",
       "0     afglms_Q1_0  25.0       0.0  0.05  248.7303  248.7303  248.7303   \n",
       "1     afglms_Q1_0  25.0       0.0  0.15  248.7303  248.7303  248.7303   \n",
       "2     afglms_Q1_0  25.0       0.0  0.30  248.7303  248.7303  248.7303   \n",
       "3     afglms_Q1_0  25.0       1.5  0.05  248.7303  248.7303  248.7303   \n",
       "4     afglms_Q1_0  25.0       1.5  0.15  248.7303  248.7303  248.7303   \n",
       "\n",
       "    0.00012   0.00026   0.00062  ...     324.0     372.0   426.0     487.0  \\\n",
       "0  248.7303  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706   \n",
       "1  248.7303  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706   \n",
       "2  248.7303  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706   \n",
       "3  248.7303  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706   \n",
       "4  248.7303  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706   \n",
       "\n",
       "      554.0     628.0     710.0     802.0     902.0    1013.0  \n",
       "0  237.8445  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "1  237.8445  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "2  237.8445  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "3  237.8445  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "4  237.8445  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4b448",
   "metadata": {},
   "source": [
    "- We don't need (or rather cannot use) the first column, which acts as an identifier for the inputs, in the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a974bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(\"atmosphere_file\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756ee40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sza</th>\n",
       "      <th>altitude</th>\n",
       "      <th>tau</th>\n",
       "      <th>2e-05</th>\n",
       "      <th>4e-05</th>\n",
       "      <th>6e-05</th>\n",
       "      <th>0.00012</th>\n",
       "      <th>0.00026</th>\n",
       "      <th>0.00062</th>\n",
       "      <th>0.00164</th>\n",
       "      <th>...</th>\n",
       "      <th>324.0</th>\n",
       "      <th>372.0</th>\n",
       "      <th>426.0</th>\n",
       "      <th>487.0</th>\n",
       "      <th>554.0</th>\n",
       "      <th>628.0</th>\n",
       "      <th>710.0</th>\n",
       "      <th>802.0</th>\n",
       "      <th>902.0</th>\n",
       "      <th>1013.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>248.7303</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0723</td>\n",
       "      <td>220.1957</td>\n",
       "      <td>225.84</td>\n",
       "      <td>232.0706</td>\n",
       "      <td>237.8445</td>\n",
       "      <td>243.4155</td>\n",
       "      <td>248.4294</td>\n",
       "      <td>252.3007</td>\n",
       "      <td>253.4411</td>\n",
       "      <td>249.7135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sza  altitude   tau     2e-05     4e-05     6e-05   0.00012   0.00026  \\\n",
       "0  25.0       0.0  0.05  248.7303  248.7303  248.7303  248.7303  248.7303   \n",
       "1  25.0       0.0  0.15  248.7303  248.7303  248.7303  248.7303  248.7303   \n",
       "2  25.0       0.0  0.30  248.7303  248.7303  248.7303  248.7303  248.7303   \n",
       "3  25.0       1.5  0.05  248.7303  248.7303  248.7303  248.7303  248.7303   \n",
       "4  25.0       1.5  0.15  248.7303  248.7303  248.7303  248.7303  248.7303   \n",
       "\n",
       "    0.00062   0.00164  ...     324.0     372.0   426.0     487.0     554.0  \\\n",
       "0  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706  237.8445   \n",
       "1  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706  237.8445   \n",
       "2  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706  237.8445   \n",
       "3  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706  237.8445   \n",
       "4  248.7303  248.7303  ...  215.0723  220.1957  225.84  232.0706  237.8445   \n",
       "\n",
       "      628.0     710.0     802.0     902.0    1013.0  \n",
       "0  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "1  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "2  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "3  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "4  243.4155  248.4294  252.3007  253.4411  249.7135  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f5f4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.dtypes.values == \"float64\").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06327078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3072ed",
   "metadata": {},
   "source": [
    "- Notice that the inputs are still in the form of a Pandas DataFrame.\n",
    "- We want to change the inputs into NumPy arrays for train / validation splits, and tf.tensors for the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788495e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce718db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544aec65",
   "metadata": {},
   "source": [
    "Next, we'll split the data into a (train | validation | test) split. To achieve this, we'll call sklearn's *train_test_split* function twice. The first call splits the data into a (train | temp) split. The second call splits the temp data into a  (validation | test) split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53e448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X, Y) ==> (train | temp)\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df15f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp ==> (validation | test)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecac3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Test data ##########\n",
      "X_train shape: (1382, 53)\n",
      "Y_train shape: (1382, 235002, 8)\n",
      "\n",
      "########## Validation data ##########\n",
      "X_val shape: (173, 53)\n",
      "Y_val shape: (173, 235002, 8)\n",
      "\n",
      "########## test data ##########\n",
      "X_test shape: (173, 53)\n",
      "Y_test shape: (173, 235002, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"########## Test data ##########\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print()\n",
    "print(\"########## Validation data ##########\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"Y_val shape: {Y_val.shape}\")\n",
    "print()\n",
    "print(\"########## test data ##########\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae0bce",
   "metadata": {},
   "source": [
    "- $\\, 80\\% \\,$ of the data is used in the training set\n",
    "- $\\, 10\\% \\,$ of the data is used in the validation set\n",
    "- $\\, 10\\% \\,$ of the data is used in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fbd75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features for numerical stability\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X_train)\n",
    "\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3fe95",
   "metadata": {},
   "source": [
    "- *MinMaxScaler* converts all feature values to the closed range [0, 1] while preserving the original distribution.\n",
    "- Note that the scaler is fit only on *X_train* to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ee2d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 16:12:57.608180: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to tf.tensors\n",
    "\n",
    "scaled_X_train = tf.cast(scaled_X_train, dtype=tf.float32)\n",
    "scaled_X_val = tf.cast(scaled_X_val, dtype=tf.float32)\n",
    "scaled_X_test = tf.cast(scaled_X_test, dtype=tf.float32)\n",
    "\n",
    "Y_train = tf.cast(Y_train, dtype=tf.float32)\n",
    "Y_val = tf.cast(Y_val, dtype=tf.float32)\n",
    "Y_test = tf.cast(Y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c1b29",
   "metadata": {},
   "source": [
    "We still need to add an extra dimension for the input data in order to be able to use convolutional layers. Currently, the input data is of shape $ (\\text{num_samples}, \\, \\text{num_features}). $\n",
    "We'll modify the shape of the input data such that\n",
    "\n",
    "$$ (\\text{num_samples}, \\, \\text{num_features}) \\quad \\boldsymbol{\\rightarrow} \\quad (\\text{num_samples}, \\, \\text{num_steps}, \\, \\text{features}), $$\n",
    "\n",
    "where\n",
    "\n",
    "- **num_samples:** the number of samples in the dataset\n",
    "- **steps:** the length of the sequence (the number of discrete data points in our sequence, i.e., the number of features per sample) (this is analogous to the number of features in our original data when each feature is treated as a separate time step)\n",
    "- **features:** the number of features to consider at each time step (we'll set this to 1)\n",
    "\n",
    "This way, the reshaped input data will have each original feature treated as a time step in the sequence, with a single feature per time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef6c03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an extra dimension to the input data\n",
    "scaled_X_train = tf.expand_dims(scaled_X_train, axis=-1)\n",
    "scaled_X_val = tf.expand_dims(scaled_X_val, axis=-1)\n",
    "scaled_X_test = tf.expand_dims(scaled_X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "964f9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_X_train min: 0.0\n",
      "scaled_X_train max: 1.0\n",
      "scaled_X_train shape: (1382, 53, 1)\n",
      "\n",
      "scaled_X_val min: 0.0\n",
      "scaled_X_val max: 1.0\n",
      "scaled_X_val shape: (173, 53, 1)\n",
      "\n",
      "scaled_X_test min: 0.0\n",
      "scaled_X_test max: 1.0\n",
      "scaled_X_test min: (173, 53, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"scaled_X_train min: {tf.reduce_min(scaled_X_train, axis=None).numpy()}\")\n",
    "print(f\"scaled_X_train max: {tf.reduce_max(scaled_X_train, axis=None).numpy()}\")\n",
    "print(f\"scaled_X_train shape: {scaled_X_train.shape}\")\n",
    "print()\n",
    "print(f\"scaled_X_val min: {tf.reduce_min(scaled_X_val, axis=None).numpy()}\")\n",
    "print(f\"scaled_X_val max: {tf.reduce_max(scaled_X_val, axis=None).numpy()}\")\n",
    "print(f\"scaled_X_val shape: {scaled_X_val.shape}\")\n",
    "print()\n",
    "print(f\"scaled_X_test min: {tf.reduce_min(scaled_X_test, axis=None).numpy()}\")\n",
    "print(f\"scaled_X_test max: {tf.reduce_max(scaled_X_test, axis=None).numpy()}\")\n",
    "print(f\"scaled_X_test min: {scaled_X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ca817",
   "metadata": {},
   "source": [
    "Next, I'll be creating the **8** different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "091a0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols_in_order = [\"tdir_down\",\"tdif_down\",\"tdir_up\",\"tdif_up\",\"spherical_albedo\",\"edir\",\"edif\",\"path_rad\"]\n",
    "output_col_indices = {col_name: idx for idx, col_name in enumerate(output_cols_in_order)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "020a99ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tdir_down': 0,\n",
       " 'tdif_down': 1,\n",
       " 'tdir_up': 2,\n",
       " 'tdif_up': 3,\n",
       " 'spherical_albedo': 4,\n",
       " 'edir': 5,\n",
       " 'edif': 6,\n",
       " 'path_rad': 7}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_col_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b5625f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_tdir_down: (1382, 235002)\n",
      "Shape of Y_val_tdir_down: (173, 235002)\n",
      "Shape of Y_test_tdir_down: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## tdir_down ##########\n",
    "\n",
    "Y_train_tdir_down = Y_train[:, :, output_col_indices[\"tdir_down\"]]\n",
    "Y_val_tdir_down = Y_val[:, :, output_col_indices[\"tdir_down\"]]\n",
    "Y_test_tdir_down = Y_test[:, :, output_col_indices[\"tdir_down\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_tdir_down: {Y_train_tdir_down.shape}\")\n",
    "print(f\"Shape of Y_val_tdir_down: {Y_val_tdir_down.shape}\")\n",
    "print(f\"Shape of Y_test_tdir_down: {Y_test_tdir_down.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "281bb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_tdif_down: (1382, 235002)\n",
      "Shape of Y_val_tdif_down: (173, 235002)\n",
      "Shape of Y_test_tdif_down: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## tdif_down ##########\n",
    "\n",
    "Y_train_tdif_down = Y_train[:, :, output_col_indices[\"tdif_down\"]]\n",
    "Y_val_tdif_down = Y_val[:, :, output_col_indices[\"tdif_down\"]]\n",
    "Y_test_tdif_down = Y_test[:, :, output_col_indices[\"tdif_down\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_tdif_down: {Y_train_tdif_down.shape}\")\n",
    "print(f\"Shape of Y_val_tdif_down: {Y_val_tdif_down.shape}\")\n",
    "print(f\"Shape of Y_test_tdif_down: {Y_test_tdif_down.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "741a50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_tdir_up: (1382, 235002)\n",
      "Shape of Y_val_tdir_up: (173, 235002)\n",
      "Shape of Y_test_tdir_up: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## tdir_up ##########\n",
    "\n",
    "Y_train_tdir_up = Y_train[:, :, output_col_indices[\"tdir_up\"]]\n",
    "Y_val_tdir_up = Y_val[:, :, output_col_indices[\"tdir_up\"]]\n",
    "Y_test_tdir_up = Y_test[:, :, output_col_indices[\"tdir_up\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_tdir_up: {Y_train_tdir_up.shape}\")\n",
    "print(f\"Shape of Y_val_tdir_up: {Y_val_tdir_up.shape}\")\n",
    "print(f\"Shape of Y_test_tdir_up: {Y_test_tdir_up.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f544c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_tdif_up: (1382, 235002)\n",
      "Shape of Y_val_tdif_up: (173, 235002)\n",
      "Shape of Y_test_tdif_up: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## tdif_up ##########\n",
    "\n",
    "Y_train_tdif_up = Y_train[:, :, output_col_indices[\"tdif_up\"]]\n",
    "Y_val_tdif_up = Y_val[:, :, output_col_indices[\"tdif_up\"]]\n",
    "Y_test_tdif_up = Y_test[:, :, output_col_indices[\"tdif_up\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_tdif_up: {Y_train_tdif_up.shape}\")\n",
    "print(f\"Shape of Y_val_tdif_up: {Y_val_tdif_up.shape}\")\n",
    "print(f\"Shape of Y_test_tdif_up: {Y_test_tdif_up.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d87b9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_spherical_albedo: (1382, 235002)\n",
      "Shape of Y_val_spherical_albedo: (173, 235002)\n",
      "Shape of Y_test_spherical_albedo: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## spherical_albedo ##########\n",
    "\n",
    "Y_train_spherical_albedo = Y_train[:, :, output_col_indices[\"spherical_albedo\"]]\n",
    "Y_val_spherical_albedo = Y_val[:, :, output_col_indices[\"spherical_albedo\"]]\n",
    "Y_test_spherical_albedo = Y_test[:, :, output_col_indices[\"spherical_albedo\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_spherical_albedo: {Y_train_spherical_albedo.shape}\")\n",
    "print(f\"Shape of Y_val_spherical_albedo: {Y_val_spherical_albedo.shape}\")\n",
    "print(f\"Shape of Y_test_spherical_albedo: {Y_test_spherical_albedo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a79a7461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_edir: (1382, 235002)\n",
      "Shape of Y_val_edir: (173, 235002)\n",
      "Shape of Y_test_edir: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## edir ##########\n",
    "\n",
    "Y_train_edir = Y_train[:, :, output_col_indices[\"edir\"]]\n",
    "Y_val_edir = Y_val[:, :, output_col_indices[\"edir\"]]\n",
    "Y_test_edir = Y_test[:, :, output_col_indices[\"edir\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_edir: {Y_train_edir.shape}\")\n",
    "print(f\"Shape of Y_val_edir: {Y_val_edir.shape}\")\n",
    "print(f\"Shape of Y_test_edir: {Y_test_edir.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fe0bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_edif: (1382, 235002)\n",
      "Shape of Y_val_edif: (173, 235002)\n",
      "Shape of Y_test_edif: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## edif ##########\n",
    "\n",
    "Y_train_edif = Y_train[:, :, output_col_indices[\"edif\"]]\n",
    "Y_val_edif = Y_val[:, :, output_col_indices[\"edif\"]]\n",
    "Y_test_edif = Y_test[:, :, output_col_indices[\"edif\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_edif: {Y_train_edif.shape}\")\n",
    "print(f\"Shape of Y_val_edif: {Y_val_edif.shape}\")\n",
    "print(f\"Shape of Y_test_edif: {Y_test_edif.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4904ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train_path_rad: (1382, 235002)\n",
      "Shape of Y_val_path_rad: (173, 235002)\n",
      "Shape of Y_test_path_rad: (173, 235002)\n"
     ]
    }
   ],
   "source": [
    "########## path_rad ##########\n",
    "\n",
    "Y_train_path_rad = Y_train[:, :, output_col_indices[\"path_rad\"]]\n",
    "Y_val_path_rad = Y_val[:, :, output_col_indices[\"path_rad\"]]\n",
    "Y_test_path_rad = Y_test[:, :, output_col_indices[\"path_rad\"]]\n",
    "\n",
    "print(f\"Shape of Y_train_path_rad: {Y_train_path_rad.shape}\")\n",
    "print(f\"Shape of Y_val_path_rad: {Y_val_path_rad.shape}\")\n",
    "print(f\"Shape of Y_test_path_rad: {Y_test_path_rad.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799292f",
   "metadata": {},
   "source": [
    "<h3>Creating the baseline NN model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da42846",
   "metadata": {},
   "source": [
    "A *baseline* model is a simple model or an existing result that one sets up when beginning a machine learning experiment. The goal is to beat this baseline model with experimenting. In deep learning, there is almost infinite amount of architectures one could create. For this reason, one of the best ways to get started is to start with something simple and see if it works with your data, and just then introduce complexity to the model as required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10646843",
   "metadata": {},
   "source": [
    "<h3>tdir_down</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c4eddb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 2s 24ms/step - loss: 0.4495 - mse: 0.4495 - val_loss: 0.1427 - val_mse: 0.1427\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.8602e-04 - val_mse: 9.8602e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 9.6233e-04 - mse: 9.6233e-04 - val_loss: 9.2387e-04 - val_mse: 9.2387e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 8.8456e-04 - mse: 8.8456e-04 - val_loss: 8.6134e-04 - val_mse: 8.6134e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 8.4498e-04 - mse: 8.4498e-04 - val_loss: 8.8989e-04 - val_mse: 8.8989e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 7.8841e-04 - mse: 7.8841e-04 - val_loss: 7.4287e-04 - val_mse: 7.4287e-04\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 7.1417e-04 - mse: 7.1417e-04 - val_loss: 6.9642e-04 - val_mse: 6.9642e-04\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 6.7703e-04 - mse: 6.7703e-04 - val_loss: 6.5661e-04 - val_mse: 6.5661e-04\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 6.3245e-04 - mse: 6.3245e-04 - val_loss: 6.4323e-04 - val_mse: 6.4323e-04\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 5.6867e-04 - mse: 5.6867e-04 - val_loss: 6.0041e-04 - val_mse: 6.0041e-04\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 5.4824e-04 - mse: 5.4824e-04 - val_loss: 5.3205e-04 - val_mse: 5.3205e-04\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 4.8785e-04 - mse: 4.8785e-04 - val_loss: 4.8732e-04 - val_mse: 4.8732e-04\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 4.5547e-04 - mse: 4.5547e-04 - val_loss: 4.6960e-04 - val_mse: 4.6960e-04\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 4.2695e-04 - mse: 4.2695e-04 - val_loss: 4.1398e-04 - val_mse: 4.1398e-04\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 3.8674e-04 - mse: 3.8674e-04 - val_loss: 3.9476e-04 - val_mse: 3.9476e-04\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 3.6892e-04 - mse: 3.6892e-04 - val_loss: 3.7104e-04 - val_mse: 3.7104e-04\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 3.3495e-04 - mse: 3.3495e-04 - val_loss: 3.4021e-04 - val_mse: 3.4021e-04\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 3.2696e-04 - mse: 3.2696e-04 - val_loss: 3.1260e-04 - val_mse: 3.1260e-04\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 2.9529e-04 - mse: 2.9529e-04 - val_loss: 2.9648e-04 - val_mse: 2.9648e-04\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.6954e-04 - mse: 2.6954e-04 - val_loss: 2.8137e-04 - val_mse: 2.8137e-04\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 2.4651e-04 - mse: 2.4651e-04 - val_loss: 2.7788e-04 - val_mse: 2.7788e-04\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 2.3901e-04 - mse: 2.3901e-04 - val_loss: 2.5387e-04 - val_mse: 2.5387e-04\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 2.1526e-04 - mse: 2.1526e-04 - val_loss: 2.2352e-04 - val_mse: 2.2352e-04\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 1.9960e-04 - mse: 1.9960e-04 - val_loss: 2.1623e-04 - val_mse: 2.1623e-04\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 1.8628e-04 - mse: 1.8628e-04 - val_loss: 2.0373e-04 - val_mse: 2.0373e-04\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 1.8245e-04 - mse: 1.8245e-04 - val_loss: 2.2248e-04 - val_mse: 2.2248e-04\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 1.7331e-04 - mse: 1.7331e-04 - val_loss: 1.9045e-04 - val_mse: 1.9045e-04\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.6659e-04 - mse: 1.6659e-04 - val_loss: 1.7558e-04 - val_mse: 1.7558e-04\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.5210e-04 - mse: 1.5210e-04 - val_loss: 1.6595e-04 - val_mse: 1.6595e-04\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.4526e-04 - mse: 1.4526e-04 - val_loss: 1.6637e-04 - val_mse: 1.6637e-04\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.3818e-04 - mse: 1.3818e-04 - val_loss: 1.7176e-04 - val_mse: 1.7176e-04\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.3355e-04 - mse: 1.3355e-04 - val_loss: 1.5613e-04 - val_mse: 1.5613e-04\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 1.2961e-04 - mse: 1.2961e-04 - val_loss: 1.6898e-04 - val_mse: 1.6898e-04\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 1.3209e-04 - mse: 1.3209e-04 - val_loss: 1.5037e-04 - val_mse: 1.5037e-04\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.2167e-04 - mse: 1.2167e-04 - val_loss: 1.3613e-04 - val_mse: 1.3613e-04\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.1992e-04 - mse: 1.1992e-04 - val_loss: 1.3168e-04 - val_mse: 1.3168e-04\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.1421e-04 - mse: 1.1421e-04 - val_loss: 1.4057e-04 - val_mse: 1.4057e-04\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.0915e-04 - mse: 1.0915e-04 - val_loss: 1.2800e-04 - val_mse: 1.2800e-04\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 1.0533e-04 - mse: 1.0533e-04 - val_loss: 1.4041e-04 - val_mse: 1.4041e-04\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 1.0181e-04 - mse: 1.0181e-04 - val_loss: 1.1429e-04 - val_mse: 1.1429e-04\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 9.8242e-05 - mse: 9.8242e-05 - val_loss: 1.1007e-04 - val_mse: 1.1007e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 9.2625e-05 - mse: 9.2625e-05 - val_loss: 1.0830e-04 - val_mse: 1.0830e-04\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 9.4052e-05 - mse: 9.4052e-05 - val_loss: 1.0864e-04 - val_mse: 1.0864e-04\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 9.2856e-05 - mse: 9.2856e-05 - val_loss: 1.1050e-04 - val_mse: 1.1050e-04\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 8.9493e-05 - mse: 8.9493e-05 - val_loss: 9.5627e-05 - val_mse: 9.5627e-05\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 8.2334e-05 - mse: 8.2334e-05 - val_loss: 9.1633e-05 - val_mse: 9.1633e-05\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 7.7555e-05 - mse: 7.7555e-05 - val_loss: 1.2438e-04 - val_mse: 1.2438e-04\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 8.1112e-05 - mse: 8.1112e-05 - val_loss: 9.0258e-05 - val_mse: 9.0258e-05\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 7.6056e-05 - mse: 7.6056e-05 - val_loss: 8.2011e-05 - val_mse: 8.2011e-05\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 6.9550e-05 - mse: 6.9550e-05 - val_loss: 8.6404e-05 - val_mse: 8.6404e-05\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 6.8921e-05 - mse: 6.8921e-05 - val_loss: 7.6328e-05 - val_mse: 7.6328e-05\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 6.5866e-05 - mse: 6.5866e-05 - val_loss: 7.8383e-05 - val_mse: 7.8383e-05\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 6.8982e-05 - mse: 6.8982e-05 - val_loss: 7.7445e-05 - val_mse: 7.7445e-05\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 6.0563e-05 - mse: 6.0563e-05 - val_loss: 7.0734e-05 - val_mse: 7.0734e-05\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 5.7906e-05 - mse: 5.7906e-05 - val_loss: 6.8637e-05 - val_mse: 6.8637e-05\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 5.6623e-05 - mse: 5.6623e-05 - val_loss: 6.1904e-05 - val_mse: 6.1904e-05\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 5.6440e-05 - mse: 5.6440e-05 - val_loss: 5.8224e-05 - val_mse: 5.8224e-05\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 5.2269e-05 - mse: 5.2269e-05 - val_loss: 5.6603e-05 - val_mse: 5.6603e-05\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 5.0016e-05 - mse: 5.0016e-05 - val_loss: 5.7300e-05 - val_mse: 5.7300e-05\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 4.9048e-05 - mse: 4.9048e-05 - val_loss: 5.3729e-05 - val_mse: 5.3729e-05\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 5.2197e-05 - mse: 5.2197e-05 - val_loss: 7.6796e-05 - val_mse: 7.6796e-05\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 4.9384e-05 - mse: 4.9384e-05 - val_loss: 5.5289e-05 - val_mse: 5.5289e-05\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 4.6517e-05 - mse: 4.6517e-05 - val_loss: 4.6838e-05 - val_mse: 4.6838e-05\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 4.4146e-05 - mse: 4.4146e-05 - val_loss: 6.0158e-05 - val_mse: 6.0158e-05\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 4.5428e-05 - mse: 4.5428e-05 - val_loss: 4.4582e-05 - val_mse: 4.4582e-05\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 3.9985e-05 - mse: 3.9985e-05 - val_loss: 4.2564e-05 - val_mse: 4.2564e-05\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 3.7975e-05 - mse: 3.7975e-05 - val_loss: 4.0517e-05 - val_mse: 4.0517e-05\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 3.7988e-05 - mse: 3.7988e-05 - val_loss: 5.2821e-05 - val_mse: 5.2821e-05\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 4.0429e-05 - mse: 4.0429e-05 - val_loss: 3.6828e-05 - val_mse: 3.6828e-05\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 3.6128e-05 - mse: 3.6128e-05 - val_loss: 4.3958e-05 - val_mse: 4.3958e-05\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 3.5813e-05 - mse: 3.5813e-05 - val_loss: 3.7321e-05 - val_mse: 3.7321e-05\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 3.4410e-05 - mse: 3.4410e-05 - val_loss: 3.7085e-05 - val_mse: 3.7085e-05\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 3.2544e-05 - mse: 3.2544e-05 - val_loss: 3.2247e-05 - val_mse: 3.2247e-05\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 3.1496e-05 - mse: 3.1496e-05 - val_loss: 3.0708e-05 - val_mse: 3.0708e-05\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 2.9706e-05 - mse: 2.9706e-05 - val_loss: 3.1381e-05 - val_mse: 3.1381e-05\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 2.9878e-05 - mse: 2.9878e-05 - val_loss: 2.9263e-05 - val_mse: 2.9263e-05\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.7264e-05 - mse: 2.7264e-05 - val_loss: 3.0075e-05 - val_mse: 3.0075e-05\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.8251e-05 - mse: 2.8251e-05 - val_loss: 3.1076e-05 - val_mse: 3.1076e-05\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.8244e-05 - mse: 2.8244e-05 - val_loss: 2.6924e-05 - val_mse: 2.6924e-05\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.7906e-05 - mse: 2.7906e-05 - val_loss: 3.1618e-05 - val_mse: 3.1618e-05\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.6030e-05 - mse: 2.6030e-05 - val_loss: 2.6394e-05 - val_mse: 2.6394e-05\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 2.6234e-05 - mse: 2.6234e-05 - val_loss: 3.7875e-05 - val_mse: 3.7875e-05\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 19ms/step - loss: 2.5267e-05 - mse: 2.5267e-05 - val_loss: 4.0517e-05 - val_mse: 4.0517e-05\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 18ms/step - loss: 2.4554e-05 - mse: 2.4554e-05 - val_loss: 2.3643e-05 - val_mse: 2.3643e-05\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Architecture of the NN model that predicts tdir_down\n",
    "model_1_tdir_down = Sequential([\n",
    "    \n",
    "    # Input layer\n",
    "    Input(shape=(53, 1)),\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    Conv1D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    MaxPool1D(pool_size=2, strides=None),\n",
    "    \n",
    "    # Flatten the 3D tensor into a 1D vector\n",
    "    Flatten(),\n",
    "    \n",
    "    # Hidden layer 3\n",
    "    Dense(units=10, activation=\"relu\"),\n",
    "    \n",
    "    # Hidden layer 4\n",
    "    Dense(units=10, activation=\"relu\"),\n",
    "    \n",
    "    # Output layer\n",
    "    Dense(units=235002, activation=\"linear\"),\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_1_tdir_down.compile(loss=MSE,\n",
    "                          optimizer=Adam(learning_rate=0.001),\n",
    "                          metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "loss_history_tdir_down_model_1 = model_1_tdir_down.fit(scaled_X_train, \n",
    "                                                       Y_train_tdir_down, \n",
    "                                                       epochs=100, \n",
    "                                                       batch_size=32,\n",
    "                                                       validation_data=(scaled_X_val, Y_val_tdir_down))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcb586",
   "metadata": {},
   "source": [
    "- Note that we don't need to specify the number of rows in the **input** or **output layer**. We only need to specify the number of units (i.e., the number of columns / dimensions). The number of rows (samples) is determined by the number of input samples we pass to the model.\n",
    "- Note that **Dense** layers (fully connected layers) in neural networks are designed to process 1D vectors. When using convolutional layer in the NN, the output will be a 3D tensor. This 3D tensors needs to be flattened into a 1D vector before passing it to a Dense layer.\n",
    "- Note that this goes the other way around as well; convolutional layers expect 3D inputs.\n",
    "- So if you are using first convolutional layers, then dense layers, and again convolutional layers, you'll have to reshape the data accordingly.\n",
    "- Note that when defining the input_shape in the input layer in a 'Sequential' model, you only need to pass the dimensions that correspond to the number of *time steps* and the number of *features*.\n",
    "\n",
    "Regarding the *batch_size* argument of the *fit* function. A **batch** is a subset of the training data that is used to train the model in one iteration of the training process. In our case, we have 1382 samples. These samples are divided into so-called **mini-batches** according to the size defined by the *batch_size* argument. In the *model_1* above, a batch_size of 32 was used. This means that there will be $\\, 1382 \\, // \\, 32 = 43 \\,$ full-sized mini-batches of size 32, and since $\\, 1382 \\, / \\, 32 = 43.1875, \\,$ the last mini-batch will be smaller. During the training process within each **epoch**, the model sees the entire dataset once. This means that there will be **44** iterations during one epoch. After each iteration (i.e., after processing one mini-batch of size 32), forward propagation and backward propagation is performed, leading to an update of the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffa36fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(loss_history):\n",
    "    \"\"\"\n",
    "    Plots the learning curve (both training and validation) of the given model.\n",
    "    \n",
    "    Args:\n",
    "    loss_history -- loss history of the given model\n",
    "    \n",
    "    Returns:\n",
    "    None.\n",
    "    \"\"\"\n",
    "    num_epochs = len(loss_history.epoch)\n",
    "    fig, ax = plt.subplots(figsize=(8,6), dpi=100)\n",
    "    ax.plot(np.arange(1, num_epochs+1), loss_history.history[\"loss\"], color=\"blue\", label=\"train loss\", linestyle=\"dashed\")\n",
    "    ax.plot(np.arange(1, num_epochs+1), loss_history.history[\"val_loss\"], color=\"black\", label=\"validation loss\")\n",
    "    ax.set_title(\"Learning curve\", size=12)\n",
    "    ax.set_xlabel(\"Number of epochs\", size=12)\n",
    "    ax.set_ylabel(\"Cost function value\", size=12)\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3051e36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(loss_history_tdir_down_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83f5f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 6ms/step - loss: 2.2587e-05 - mse: 2.2587e-05\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3643e-05 - mse: 2.3643e-05\n",
      "Train MSE: 2.258678068756126e-05\n",
      "Validation MSE: 2.3642980522708967e-05\n"
     ]
    }
   ],
   "source": [
    "# model_1_tdir_down performance\n",
    "train_loss, train_mse = model_1_tdir_down.evaluate(scaled_X_train, Y_train_tdir_down)\n",
    "val_los, val_mse = model_1_tdir_down.evaluate(scaled_X_val, Y_val_tdir_down)\n",
    "\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
