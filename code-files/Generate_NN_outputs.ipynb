{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d75dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5565ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One output matrix (to get the column names of the output data)\n",
    "output1 = pd.read_json(\"/fmi/projappl/project_2004400/jamin/data/libradtran_data/NN_data/output_params/afglms_Q1_0_sza25_vza1.0_phi0_phi00_alt0_tau0.05.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119ffa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wavelength',\n",
       " 'rho0',\n",
       " 'rho1',\n",
       " 'rho2',\n",
       " 'tdir_down',\n",
       " 'tdif_down',\n",
       " 'tdir_up',\n",
       " 'tdif_up',\n",
       " 'spherical_albedo',\n",
       " 'edir',\n",
       " 'edif',\n",
       " 'path_rad',\n",
       " 'albedo1',\n",
       " 'albedo2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_cols = output1.columns.values.tolist()\n",
    "output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515eac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_outputs_full(output_folder_path):\n",
    "    \"\"\"\n",
    "    Generates an output tensor of shape (1728, 235002, 14).\n",
    "    \n",
    "    Args:\n",
    "        output_folder_path: path to the folder containing the libradtran output files\n",
    "        \n",
    "    Returns:\n",
    "        output_tensor: tensor of shape (1728, 235002, 14).\n",
    "    \"\"\"\n",
    "    output_files_list = sorted(os.listdir(output_folder_path))\n",
    "    Y = np.zeros((1728, 235002, 14))\n",
    "    for i, file in enumerate(output_files_list):\n",
    "        full_path = output_folder_path + file\n",
    "        M = pd.read_json(full_path).values\n",
    "        Y[i, :, :] = M\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e838b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = \"/fmi/projappl/project_2004400/jamin/data/libradtran_data/NN_data/output_params/\"\n",
    "outputs_full = gen_outputs_full(output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90511d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 235002, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4ff814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_HDF5(Y, save_loc, file_name):\n",
    "    \"\"\"\n",
    "    Saves the given NumPy array into the desired location in HDF5 format.\n",
    "    \n",
    "    Args:\n",
    "        Y: NumPy array\n",
    "        save_loc: the path to the desired saving location\n",
    "        file_name: name of the saved file\n",
    "        \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    full_path = save_loc + file_name\n",
    "    with h5py.File(full_path, \"w\") as hf:\n",
    "        hf.create_dataset(\"output_data\", data=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bac7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_save_loc = \"/fmi/projappl/project_2004400/jamin/data/libradtran_data/NN_data/\"\n",
    "output_file_name = \"outputs_full.h5\"\n",
    "save_HDF5(Y=outputs_full, save_loc=output_save_loc, file_name=output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2739785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HDF5(file_path):\n",
    "    \"\"\"\n",
    "    Loads in the outputs of the NN model that are in .h5 format.\n",
    "    \n",
    "    Args:\n",
    "        file_path: location of the outputs\n",
    "        \n",
    "    Returns:\n",
    "        data: a NumPy array.\n",
    "    \"\"\"\n",
    "    with h5py.File(name=file_path, mode=\"r\") as hf:\n",
    "        data = hf[\"output_data\"][:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c39778",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_path = \"/fmi/projappl/project_2004400/jamin/data/libradtran_data/NN_data/outputs_full.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b06b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs\n",
    "Y = load_HDF5(outputs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef6a457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 235002, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ec4d1",
   "metadata": {},
   "source": [
    "<h3>Dealing with missing values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0996b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_w_nans(Y):\n",
    "    \"\"\"\n",
    "    Checks which columns contain nans (spoiler alert, only spherical albedo contains nans).\n",
    "    \n",
    "    Args:\n",
    "        Y: a NumPy array (tensor)\n",
    "        \n",
    "    Returns:\n",
    "        None.\n",
    "        \n",
    "    Prints:\n",
    "        Columns that contain nan values.\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    for i in range(Y.shape[0]):\n",
    "        df = pd.DataFrame(Y[i, :, :], columns=output_cols)\n",
    "        cols_w_nans = df.columns[df.isna().any()]\n",
    "        for col in cols_w_nans:\n",
    "            if col != \"spherical_albedo\":\n",
    "                print(col)\n",
    "                flag = True\n",
    "    if not flag:\n",
    "        print(\"Only spherical albedo contains nans.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77afe8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only spherical albedo contains nans.\n"
     ]
    }
   ],
   "source": [
    "columns_w_nans(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809063c",
   "metadata": {},
   "source": [
    "Most likely, the reason that spherical_albedo contains nans is that it is computed as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{spherical albedo} = \\frac{\\text{albedo1} \\, * \\, (\\text{rho2} - \\text{rho0}) \\, * \\, \\text{albedo2} \\, * \\, (\\text{rho1} - \\text{rho0})}{\\text{albedo2} \\, * \\, \\text{albedo1} \\, * \\, (\\text{rho2} - \\text{rho1})}.\n",
    "\\end{align*}\n",
    "\n",
    "After some investigating, it looks like that the rows where $\\, \\text{spherical_albedo} = \\text{nan}, \\,$ $\\, \\text{rho2} \\,$ and $\\, \\text{rho1} \\,$ are equal to each other, meaning that in the spherical albedo calculation, there is division by zero. To deal with this, I am going to alter the data such that \n",
    "\n",
    "    \n",
    "``` python\n",
    "if (rho1 == rho2) or (rho1 == rho0) or (rho2 == rho0):\n",
    "    spherical_albedo = 0\n",
    "```\n",
    "\n",
    "Hopefully after this, the nans are gone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732dd50",
   "metadata": {},
   "source": [
    "<h3>Replace the missing values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf662bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nans(Y):\n",
    "    \"\"\"\n",
    "    Replaces the nan values in spherical_albedo with 0,\n",
    "    if  (rho1 == rho2) or (rho1 == rho0) or (rho2 == rho0).\n",
    "    \n",
    "    Args:\n",
    "        Y: a NumPy array (tensor)\n",
    "        \n",
    "    Returns:\n",
    "        Y: a new NumPy array.\n",
    "        \n",
    "    Notes:\n",
    "        - rho0 is located in the 2nd col (index position 1)\n",
    "        - rho1 is located in the 3rd col (index position 2)\n",
    "        - rho2 is located in the 4th col (index position 3)\n",
    "        - spherical_albedo is located in the 9th col (index position 8)\n",
    "        - The matrices are modified inplace.\n",
    "    \"\"\"\n",
    "    for matrix in Y:\n",
    "        for row in matrix:\n",
    "            rho0 = row[1]\n",
    "            rho1 = row[2]\n",
    "            rho2 = row[3]\n",
    "            if (rho1 == rho2) or (rho1 == rho0) or (rho2 == rho0):\n",
    "                # Set spherical_albedo to zero\n",
    "                row[8] = 0\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db88a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_modified = replace_nans(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070ead7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nans(Y):\n",
    "    \"\"\"\n",
    "    Checks if the given NumPy array contains any nans.\n",
    "    \n",
    "    Args:\n",
    "        Y: a NumPy array\n",
    "        \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    for i, matrix in enumerate(Y):\n",
    "        if np.isnan(matrix).any():\n",
    "            print(f\"Matrix with index {i} contains missing values.\")\n",
    "            flag = True\n",
    "    if not flag:\n",
    "        print(\"The given tensor does not contain any missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ede70876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given tensor does not contain any missing values.\n"
     ]
    }
   ],
   "source": [
    "check_nans(Y_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f1cf240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wavelength': 0,\n",
       " 'rho0': 1,\n",
       " 'rho1': 2,\n",
       " 'rho2': 3,\n",
       " 'tdir_down': 4,\n",
       " 'tdif_down': 5,\n",
       " 'tdir_up': 6,\n",
       " 'tdif_up': 7,\n",
       " 'spherical_albedo': 8,\n",
       " 'edir': 9,\n",
       " 'edif': 10,\n",
       " 'path_rad': 11,\n",
       " 'albedo1': 12,\n",
       " 'albedo2': 13}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column index positions of the libradtran output variables\n",
    "output_vars_col_idx = {col_name: idx for idx, col_name in enumerate(output1.columns)}\n",
    "output_vars_col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97e40112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset(Y):\n",
    "    \"\"\"\n",
    "    Creates a subset of the output data.\n",
    "    Note that we are interested in predicting the following libradtran outputs:\n",
    "    tdir_down, tdif_down, tdir_up, tdif_up, spherical_albedo, edir, edif, path_rad.\n",
    "        \n",
    "    Args:\n",
    "        Y: the full output data (tensor) containing all the libradtran output variables\n",
    "        \n",
    "    Returns:\n",
    "        Y_subset: subset of the full output data containing only the output variables of interest.\n",
    "    \"\"\"\n",
    "    # Column indices of the libradtran output variables of interest\n",
    "    tdir_down = output_vars_col_idx[\"tdir_down\"]\n",
    "    tdif_down = output_vars_col_idx[\"tdif_down\"]\n",
    "    tdir_up = output_vars_col_idx[\"tdir_up\"]\n",
    "    tdif_up = output_vars_col_idx[\"tdif_up\"]\n",
    "    spherical_albedo = output_vars_col_idx[\"spherical_albedo\"]\n",
    "    edir = output_vars_col_idx[\"edir\"]\n",
    "    edif = output_vars_col_idx[\"edif\"]\n",
    "    path_rad = output_vars_col_idx[\"path_rad\"]\n",
    "    \n",
    "    # Index the desired subset from the full output data\n",
    "    Y_subset = Y[:, :, [tdir_down, tdif_down, tdir_up, tdif_up, spherical_albedo, edir, edif, path_rad]]\n",
    "    \n",
    "    return Y_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157775f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_subset = create_subset(Y_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "805755c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 235002, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342e9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_HDF5(Y=Y_subset,\n",
    "          save_loc=\"/fmi/projappl/project_2004400/jamin/data/libradtran_data/NN_data/\",\n",
    "          file_name=\"outputs_subset.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
